services:
  settingdb:
    image: json-server:latest
    #container_name: ntfyr-settingdb
    build:
      context: .
      dockerfile: ./docker/Dockerfile.settingdb
    ports:
      - "3000:3000"
    volumes:
      - settingdb-data:/data

  redis:
    image: redis #Queue for the taks
    #container_name: ntfyr-redis
    restart: always
    ports:
      - 6379:6379
    volumes:
      - redis-data:/data

  redis-commander:
    container_name: redis-commander
    hostname: redis-commander
    image: rediscommander/redis-commander:latest
    restart: always
    depends_on:
      - redis
    environment:
      - REDIS_HOSTS=local:redis:6379
    ports:
      - 6060:6060

  reacherhq:
    image: reacherhq/backend
    container_name: reacherhq
    ports:
      - "8040:8040"

  mongodb:
    image: mongo:latest
    #container_name: ntfyr-mongo
    restart: always
    ports:
      - "27017:27017"
    volumes:
      - mongo-data:/data/db
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_INITDB_ROOT_USERNAME}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_INITDB_ROOT_PASSWORD}

  postgres:
    build:
      context: .
      dockerfile: docker/Dockerfile.postgres
    image: postgres:15
    #container_name: ntfyr-postgres
    restart: always
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: notifyr


  vault:
    build:
      context: .
      dockerfile: ./docker/Dockerfile.vault
    container_name: ntfyr-vault
    labels:
      - com.docker.compose.service=vault
    image: hashicorp/vault:1.16
    cap_add: ["IPC_LOCK"]
    ports:
      - "8200:8200"
    environment:
      VAULT_ADDR: "http://0.0.0.0:8200"
      VAULT_CONTAINER_READY: "false"
    volumes:
      - vault-data:/vault/data
      - vault-shared:/vault/shared
      - vault-secrets:/vault/secrets
      - vault-audit:/vault/logs
    secrets:
      - approle_role_id
    #restart: always
    #stop_grace_period: 5m
    healthcheck:
      test: ["CMD-SHELL", '[ "$VAULT_CONTAINER_READY" = "true" ]']
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s

  pgadmin:
    image: dpage/pgadmin4
    container_name: pgadmin
    restart: always
    hostname: pgadmin
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_DEFAULT_EMAIL}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_DEFAULT_PASSWORD}
    ports:
      - "7070:7070"
    depends_on:
      - postgres

  worker:
    image: notifyr:celery
    command: ["./spawn_celery_worker.sh", "1", "false"]
    #container_name: ntfyr-worker
    # deploy:
    #   replicas: 3
    # labels:
    #   - "com.docker.compose.service=worker"
    build:
      context: .
      dockerfile: docker/Dockerfile.celery
    restart: always
    environment:
      - MODE=prod
    env_file:
      - .env
    depends_on:
      - redis
      # - beat

  beat:
    image: notifyr:redbeat
    command: ["make", "redbeat"]
    #container_name: ntfyr-redbeat
    # labels:
    #   - com.docker.compose.service=beat
    build:
      context: .
      dockerfile: docker/Dockerfile.celery
    restart: always
    environment:
      - MODE=prod
    env_file:
      - .env
    depends_on:
      - redis

  flower:
    image: notifyr:flower
    command: ["make", "flower"]
    #container_name: ntfyr-flower
    # labels:
    #   - com.docker.compose.servie=flower
    build:
      context: .
      dockerfile: docker/Dockerfile.celery
    restart: always
    env_file:
      - .env
    depends_on:
      - redis
    ports:
      - "5555:5555"

  neo4j:
    image: neo4j:5.15
    container_name: ntfyr-neo4j
    restart: unless-stopped
    ports:
      - "7687:7687"
      - "7474:7474"
    environment:
      - NEO4J_AUTH=${NEO4J_AUTH}
      - NEO4J_dbms_memory_heap_initial__size=512m
      - NEO4J_dbms_memory_heap_max__size=1G
      - NEO4J_dbms_memory_pagecache_size=512m
      - NEO4J_dbms_default__database=${NEO4J_DATABASE}

    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
      - neo4j_conf:/conf

  prometheus:
    image: prom/prometheus
    container_name: prometheus
    restart: always
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml

  pgbouncer:
    image: edoburu/pgbouncer
    #container_name: ntfyr-pgbouncer
    restart: always
    ports:
      - "6432:6432" # PgBouncer listens on port 6432
    volumes:
      - ./docker/pgbouncer.ini:/etc/pgbouncer/pgbouncer.ini
      - ./docker/userlist.txt:/etc/pgbouncer/userlist.txt
    environment:
      - DB_HOST=ntfyr-postgres
      - DB_PORT=5432
      - DB_USER=${POSTGRES_USER}
      - DB_PASSWORD=${POSTGRES_PASSWORD}
    depends_on:
      - postgres

  app:
    image: notifyr:fastapi
    #container_name: ntfyr-app
    labels:
      - "com.docker.compose.service=app"
    command: ["python", "main.py", "-H=0.0.0.0", "-p=8088", "-t=solo"]
    #command: ['uvicorn', 'main:app', '--workers' ,'${WORKERS_COUNT}','--host','0.0.0.0','--port' ,'8088']
    ports:
      - 8088:8088
    volumes:
      - ./rate_limits.json:/run/secrets/rate_limits:ro
    build:
      context: ./
      dockerfile: Dockerfile
    environment:
      - MODE=prod
    env_file:
      - .env
    depends_on:
      - redis
      - mongodb

  # balancer:
  #   #container_name: ntfyr-balancer
  #   build:
  #     context: .
  #     dockerfile: docker/Dockerfile.balancer
  #   env_file:
  #     - ./balancer/.env
  #   ports:
  #     - 8080:8080

volumes:
  vault-data: {}
  vault-shared: {} # holds secret_id
  vault-secrets: {} # holds root_token/unseal_key (optional, only for admin access)
  vault-audit: {}

  mongo-data:
    driver: local

  postgres-data:
    driver: local

  assets-data:
    driver: local

  settingdb-data:

  neo4j_data:
  neo4j_logs:
  neo4j_conf:
  redis-data:
    driver: local

secrets:
  approle_role_id:
    file: ./bootstrap/role_id.txt # created after first container init
